---
title: "Felony Category Multi-classification"
author: "Sarah Krause and Minji Kang"
format:
  html:
    embed-resources: true
editor: visual
execute:
  warning: false
---

These first two code chunks do not need to be merged / copied and pasted into the index file (just loading libraries and reading in the data).

```{r}
library(tidyverse)
library(readr)
library(haven)
library(lubridate)
library(tidymodels)
library(tidycensus)
library(janitor)
library(sf)
library(plotly)
library(themis)
library(vip)
library(ranger)
library(xgboost)
library(rlang)
```

```{r}
# read in the data

crime <- read_csv("data/crime_enriched_acs_nona.csv")

#crime <- read_csv("~/Desktop/final-project/data/crime_enriched_acs_nona.csv")

```

In addition to knowing whether a crime is a felony, it is also useful for law enforcement to know the severity of the felony, since several different crime categories are classified as felonies and each require different resources and police response.

In this section, we will build on the binary classification of crimes as felony or not felony by creating a multi-classification model to classify crimes based on the felony severity level. The outcome variable is 'felony_severity,' which was derived from the 'offense' variable in the Crime Incidents datasets (2008-2025) from DC Open Data. Felony_severity contains seven different severity levels, ranging from 0 (not a felony) to 7 (homicide) (See appendix). However, our multiclass classification candidate models will only include felonies, so felony severity level 0 will be removed from the dataset.

The goal of this multi-classification model is to further enhance the ability of law enforcement in DC to effectively allocate resources by forecasting the relative severity of different felonies committed in the District.

Replicating the steps used above for the binary classification model, we split the data to use 2019-2022 for training and 2023 for testing and implementation. We selected the same predictor variables used above from the 'crime_enriched_acs_nona' merged dataset.

## Prepare the Data

```{r}
# Select variables of interest for modeling
multiclass_vars <- c(
  "felony_severity", # outcome variable
  "x", "y", "latitude", "longitude", "year",
  "shift", "method", "tract", "report_date_parsed",

  # GIS contextual features
  "in_liquor_moratorium_zone", "nearest_liquorstore_dist", "near_liquorstore_200m",
  "near_wifi_100m", "nearest_wifi_dist",
  "in_lowfood_zone",
  "nearest_grocery_dist", "near_grocery_300m",
  "nearest_bank_dist",
  "near_bank_250m", 
  "in_vending_zone", 
  "police_sector", 
  "in_military_base",

  # ACS socioeconomic features
  "median_income", "poverty_rate", "unemployed_rate", 
  "singlemom_pct",
  "renter_pct", "no_vehicle_pct", 
  "black_pct", "hispanic_pct","foreign_born_pct", 
  "hsplus_pct", 
  "under18_pct", "age65plus_pct"
)

# Keep only selected variables
crime_multiclass <- crime |> 
  select(all_of(multiclass_vars)) |>
  filter(felony_severity > 0)

# Define training data (2019-2022)
crime_multiclass_small <- crime_multiclass |>
  filter(year >= 2019, year < 2023)

# Define implementation/test data (2023)
crime_multiclass_implement <- crime_multiclass |>
  filter(year == 2023)

# Adjust variable data types for training data
crime_multiclass_small <- crime_multiclass_small |> 
  mutate(
    report_date_parsed = as.Date(report_date_parsed),
         felony_severity = factor(felony_severity)
         )

# Adjust variable data types for implementation data
crime_multiclass_implement <- crime_multiclass_implement |> 
  mutate(
    report_date_parsed = as.Date(report_date_parsed),
         felony_severity = factor(felony_severity)
         )
```

### Split Data

```{r}
set.seed(123)

multiclass_split <- initial_split(crime_multiclass_small, prop = 0.8, strata = felony_severity)

multiclass_train <- training(multiclass_split)

multiclass_test <- testing(multiclass_split)
```

### EDA on Training Set

First, we examine the distribution of the outcome variable `felony_severity`.

```{r}
# Check class imbalance in the target variable
multiclass_train |> 
  count(felony_severity) |> 
  mutate(pct = n / sum(n))

ggplot(multiclass_train, aes(x = felony_severity)) +
  geom_bar() +
  scale_y_continuous(n.breaks = 10) +
  labs(title = "Number of Felonies in Each Category",
       x = "Felony Severity Category",
       y = "Count") +
  theme_minimal()

```

40% of the crimes are classified as felony severity 1, corresponding to 'motor vehicle theft,' which is the lowest severity level among felonies.

# Select Error Metric

For our multi-classification problem, accuracy is the most appropriate error metric, measuring how often the classifier is correct. Accuracy is defined as:

$$
\frac{\text{TP}}{\text{total}}
$$

True positives are defined as the cases where the model correctly classifies crimes as 0, 1, 2, 3, 4, 5, 6, or 7 felony severity, and total is the total number of predictions.

## Candidate Model 1: Random Forest Model

Our first model is a random forest model using all of the predictors included in the dataset to predict the felony severity. Because felony severity level 1 is disproportionately represented in the dataset, we will downsample felony_severity.

```{r}
# recipe
random_newrecipe <- recipe(formula = felony_severity ~ ., data = multiclass_train) |>
  step_downsample(felony_severity) |>
  step_rm(report_date_parsed) |>
  step_mutate(method = factor(method)) |>
  step_dummy(all_nominal_predictors()) |>
  step_normalize(all_numeric_predictors())

# model
random_model <- rand_forest(
  trees = 200, 
  mtry = 2,
  min_n = 5) |>
  set_mode("classification") |>
  set_engine("ranger",
             importance = "impurity",
             num.threads = 4)

# workflow 
random_wf <- workflow() |>
  add_recipe(random_newrecipe) |>
  add_model(random_model)

# fit the model
random_fit <- random_wf |>
  fit(data = multiclass_train)

# generate predictions 
random_pred <- predict(random_fit, multiclass_test, type = "class") |>
  bind_cols(multiclass_test)

# calculate metrics 
random_pred |>
  recall(truth = felony_severity, estimate = .pred_class)

random_pred |>
  precision(truth = felony_severity, estimate = .pred_class)

random_pred

conf_mat(data = random_pred,
         truth = felony_severity,
         estimate = .pred_class)

accuracy(data = random_pred, truth = felony_severity, estimate = .pred_class)

```

The overall accuracy rate for our random forest model is 23.08%, showing that overall, the model is has a weak ability to predict the accurate felony severity category.

Looking at the confusion matrix, we can see what is driving this low accuracy rate.

```{r}
random_pred |>
  filter(felony_severity == 1) |>
  accuracy(truth = felony_severity, estimate = .pred_class)
```

However, the model is not good at predicting the other felony classes:

I want to write a custom function but it's not working:

multiclass_metrics(random_pred, felony_severity, 1, .pred_class) multiclass_metrics \<- function(x, truth, category, estimate) {

filtered_dataset \<- x \|\> filter(truth == category)

accuracy \<- accuracy(data = filtered_dateset, truth = truth, estimate = estimate)

recall \<- recall(data = filtered_dataset, truth = truth, estimate = estimate)

precision \<- precision(data = filtered_dataset, truth = truth, estimate = estimate)

return(accuracy, recall, precision)

multiclass_metrics(x = random_pred, truth = felony_severity, category = 1) estimate = .pred_class)

```{r}
# Variable importance for random forest
random_fit |>
  extract_fit_parsnip() |>
  vip(num_features = 20) %>% #we are using this pipe to make sure the argument works
  .$data |>
  mutate (
    importance = Importance / max(Importance),
    variable = fct_reorder(Variable, importance)
  ) |>
  ggplot(aes(x = importance, y = variable, fill = importance)) +
  geom_col() +
  labs(
    title = "variable importance of random forest",
    x = "normalized importance",
    y = "variable"
  )
```

Method: 'others' is the most important factor, with a normalized importance of 1. This value indicates that the crime was not committed with a knife or gun.

I want to create some kind of visualization or something to show why that might be happening.

## Candidate Model 2: CART Model

Our second candidate model is a CART (classification and regression tree) model, stratified on felony_severity because the felony_severity classes are not equal. We will use five-fold cross-validation and tune tree depth, cost complexity, and the minimum number of nodes to optimize the model.

```{r}
# cross-validation
set.seed(123)
cross_validation <- vfold_cv(multiclass_train, v = 5, strata = felony_severity)

# recipe
cart_newrecipe <- recipe(formula = felony_severity ~ ., data = multiclass_train) |>
  step_downsample(felony_severity) |>
  step_rm(report_date_parsed) |>
  step_mutate(method = factor(method)) |>
  step_dummy(all_nominal_predictors()) |>
  step_normalize(all_numeric_predictors())

# cart model object
cart_model <- decision_tree(
  tree_depth = tune(),
  cost_complexity = tune(),
  min_n = tune()
) |>
  set_engine(engine = "rpart") |>
  set_mode(mode = "classification")

# set up tuning grid
cart_grid <- grid_regular(
  cost_complexity(range = c(0.0001, 0.1)),
  tree_depth(range = c(3, 15)),
  min_n(),
  levels = 5
)

# cart workflow
cart_wf <- workflow() |>
  add_recipe(cart_newrecipe) |>
  add_model(cart_model)

# test and choose best hyperparameters
cart_test <- cart_wf |>
  tune_grid(resamples = cross_validation,
            grid = cart_grid,
            metrics = metric_set(recall, roc_auc, accuracy))

cart_test |>
  collect_metrics()

cart_test |>
  show_best()

# finalize workflow
final_cart_wf <- cart_wf |>
  finalize_workflow(select_best(cart_test)
)

# fit
cart_fit <- final_cart_wf |>
  fit(data = multiclass_train)

# predictions
predictions <- bind_cols(
  multiclass_test,
  predict(object = cart_fit, new_data = multiclass_test),
  predict(object = cart_fit, new_data = multiclass_test, type = "prob")
) 
select(predictions, felony_severity, starts_with(".pred"))

# confusion matrix
conf_mat(data = predictions,
         truth = felony_severity,
         estimate = .pred_class)

# recall and precision
recall(data = predictions,
       truth = felony_severity,
       estimate = .pred_class)

precision(data = predictions,
          truth = felony_severity,
          estimate = .pred_class)

accuracy(data = predictions,
         truth = felony_severity,
         estimate = .pred_class)

```

Our CART model is only correctly predicting the majority class (felony_severity = 1), and therefore not learning the minority classes. This is likely due to the class imbalance, even though we downsampled felony severity. 

## Candidate Model 3: KNN Model

```{r}
# recipe
knn_newrecipe <- recipe(formula = felony_severity ~ ., data = multiclass_train) |>
  step_downsample(felony_severity) |>
  step_rm(report_date_parsed) |>
  step_mutate(method = factor(method)) |>
  step_zv(all_predictors()) |>
  step_novel(all_factor_predictors()) |>
  step_dummy(all_nominal_predictors()) |>
  step_normalize(all_numeric_predictors()) 

# model
knn_model <- nearest_neighbor( neighbors = 5) |>
  set_engine(engine = "kknn") |>
  set_mode(mode = "classification")

# workflow
knn_wf <- workflow() |>
  add_recipe(knn_newrecipe) |>
  add_model(knn_model)

# fit the model
knn_fit <- fit(knn_wf, data = multiclass_train)

# generate predictions
knn_preds <- predict(knn_fit, new_data = multiclass_test, type = "class") |>
  bind_cols(multiclass_test)

# calculate metrics 
conf_mat(data = knn_preds, truth = felony_severity, estimate = .pred_class)

metrics(knn_preds, truth = felony_severity, estimate = .pred_class)

```
The accuracy rate is 19.49% for the KNN model. 

```{r}

# map first try?

crime_sf <- crime |>
  st_as_sf(coords = c("longitude", "latitude"))

ggplot(data = crime_sf) +
  geom_sf(aes(color = felony_severity), alpha = 0.5) +
  theme_minimal()

```
